# Example Cloud Run service configuration for Consensus Engine Pipeline Worker
#
# This file demonstrates how to deploy the Pub/Sub worker as a Cloud Run service
# that processes messages from a Pub/Sub subscription.
#
# Docker Image:
#   Build: docker build -t gcr.io/PROJECT_ID/consensus-worker:TAG -f Dockerfile.worker .
#   Push:  docker push gcr.io/PROJECT_ID/consensus-worker:TAG
#
# Usage:
#   1. Build and push Docker image to Google Container Registry or Artifact Registry
#   2. Replace placeholders with your actual values (PROJECT_ID, REGION, INSTANCE_NAME, etc.)
#   3. Create secrets in Secret Manager (openai-api-key)
#   4. Create Pub/Sub topic and subscription (see docs/WORKER_DEPLOYMENT.md)
#   5. Deploy: gcloud run services replace worker-service.yaml
#   6. Grant necessary IAM roles to the worker service account:
#      - roles/cloudsql.client (for Cloud SQL access)
#      - roles/pubsub.subscriber (for Pub/Sub subscription)
#      - roles/secretmanager.secretAccessor (for accessing secrets)
#
# Note: This worker runs as a long-running Cloud Run service that pulls messages
# from Pub/Sub. Alternatively, consider using Cloud Run Jobs for batch processing.

apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: consensus-worker
  namespace: 'PROJECT_ID'  # Replace with your GCP project ID
  labels:
    cloud.googleapis.com/location: us-central1
  annotations:
    run.googleapis.com/ingress: internal
    run.googleapis.com/ingress-status: internal
spec:
  template:
    metadata:
      annotations:
        # Scaling configuration
        autoscaling.knative.dev/minScale: '1'  # Keep at least 1 instance running
        autoscaling.knative.dev/maxScale: '3'  # Limit max workers
        
        # CPU allocation (always allocated for worker responsiveness)
        run.googleapis.com/cpu-throttling: 'false'
        
        # Execution environment (Second generation recommended)
        run.googleapis.com/execution-environment: gen2
        
        # Cloud SQL connection
        run.googleapis.com/cloudsql-instances: 'PROJECT_ID:REGION:INSTANCE_NAME'
        
        # VPC connector (if needed for VPC access)
        # run.googleapis.com/vpc-access-connector: 'projects/PROJECT_ID/locations/REGION/connectors/CONNECTOR_NAME'
        # run.googleapis.com/vpc-access-egress: 'private-ranges-only'
    spec:
      containerConcurrency: 1  # Process one job at a time per instance
      timeoutSeconds: 3600  # Allow long-running jobs (1 hour max)
      serviceAccountName: 'consensus-worker-sa@PROJECT_ID.iam.gserviceaccount.com'  # Replace
      containers:
      - name: consensus-worker
        # Docker image built from Dockerfile.worker
        # Build: docker build -t gcr.io/PROJECT_ID/consensus-worker:TAG -f Dockerfile.worker .
        # Or use Artifact Registry: REGION-docker.pkg.dev/PROJECT_ID/REPO/consensus-worker:TAG
        image: 'gcr.io/PROJECT_ID/consensus-worker:latest'  # Replace with your image
        ports:
        - name: http1
          containerPort: 8080
        env:
        # OpenAI Configuration
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: openai-api-key
              key: latest
        - name: OPENAI_MODEL
          value: 'gpt-5.1'
        - name: TEMPERATURE
          value: '0.7'
        - name: EXPAND_MODEL
          value: 'gpt-5.1'
        - name: EXPAND_TEMPERATURE
          value: '0.7'
        - name: REVIEW_MODEL
          value: 'gpt-5.1'
        - name: REVIEW_TEMPERATURE
          value: '0.2'
        - name: AGGREGATE_MODEL
          value: 'gpt-5.1'
        - name: AGGREGATE_TEMPERATURE
          value: '0.0'
        
        # Environment
        - name: ENV
          value: 'production'
        
        # Database Configuration (Cloud SQL)
        - name: USE_CLOUD_SQL_CONNECTOR
          value: 'true'
        - name: DB_INSTANCE_CONNECTION_NAME
          value: 'PROJECT_ID:REGION:INSTANCE_NAME'  # Replace
        - name: DB_NAME
          value: 'consensus_engine'
        - name: DB_USER
          value: 'consensus-worker-sa@PROJECT_ID.iam'  # IAM user
        - name: DB_IAM_AUTH
          value: 'true'
        - name: DB_POOL_SIZE
          value: '5'
        - name: DB_MAX_OVERFLOW
          value: '10'
        - name: DB_POOL_TIMEOUT
          value: '30'
        - name: DB_POOL_RECYCLE
          value: '3600'
        
        # Pub/Sub Configuration
        - name: PUBSUB_PROJECT_ID
          value: 'PROJECT_ID'  # Replace
        - name: PUBSUB_SUBSCRIPTION
          value: 'consensus-engine-jobs-sub'
        - name: PUBSUB_USE_MOCK
          value: 'false'
        
        # Worker Configuration
        - name: WORKER_MAX_CONCURRENCY
          value: '10'
        - name: WORKER_ACK_DEADLINE_SECONDS
          value: '600'
        - name: WORKER_STEP_TIMEOUT_SECONDS
          value: '300'
        - name: WORKER_JOB_TIMEOUT_SECONDS
          value: '1800'
        - name: MAX_RETRIES_PER_PERSONA
          value: '3'
        - name: RETRY_INITIAL_BACKOFF_SECONDS
          value: '1.0'
        - name: RETRY_BACKOFF_MULTIPLIER
          value: '2.0'
        
        resources:
          limits:
            cpu: '2000m'
            memory: '4Gi'
        
        # Basic health check (worker doesn't have HTTP endpoints by default)
        # Could implement a simple health check server or use exec-based checks
        livenessProbe:
          exec:
            command:
            - python
            - -c
            - "import sys; sys.exit(0)"
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        
        startupProbe:
          exec:
            command:
            - python
            - -c
            - "import sys; sys.exit(0)"
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 10
          failureThreshold: 12  # Allow up to 120 seconds for startup
  
  traffic:
  - percent: 100
    latestRevision: true
